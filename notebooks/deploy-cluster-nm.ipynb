{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import inflection\n",
    "import re\n",
    "import umap as umap\n",
    "\n",
    "from sklearn import cluster as c\n",
    "from sklearn import metrics \n",
    "from sklearn import ensemble as en\n",
    "\n",
    "import s3fs\n",
    "import fs\n",
    "\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_s3 = 's3://s3-mentoria-deploy'\n",
    "data = pd.read_excel( 's3://menotria-cluster-s3/Online Retail.xlsx' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_old = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
    "       'UnitPrice', 'CustomerID', 'Country']\n",
    "snakecase = lambda x: inflection.underscore( x ) # function to snakecase\n",
    "cols_news = list( map( snakecase, cols_old ))\n",
    "df1.columns = cols_news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Check NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Replace NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 0\n",
      "Not Missing: 406829\n"
     ]
    }
   ],
   "source": [
    "# remove na\n",
    "df1 = df1.dropna(subset=['description', 'customer_id'])\n",
    "df_missing = df1[df1['customer_id'].isna()]\n",
    "print(f'Missing: {df_missing.shape[0]}')\n",
    "print(f'Not Missing: {df1.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace Na\n",
    "# create reference\n",
    "backup = pd.DataFrame(df_missing['invoice_no'].drop_duplicates())\n",
    "backup['customer_id'] = np.arange(19000, 19000+len(backup), 1)\n",
    "\n",
    "# merge original data frame\n",
    "df1 = pd.merge(df1, backup, on='invoice_no', how='left')\n",
    "\n",
    "#coalesce\n",
    "df1['customer_id'] = df1['customer_id_x'].combine_first(df1['customer_id_y'])\n",
    "\n",
    "# drop columns\n",
    "df1 = df1.drop(columns=['customer_id_x', 'customer_id_y'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Change dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoice date\n",
    "df1['invoice_date'] = pd.to_datetime( df1['invoice_date'], format='%d-%b-%y' )\n",
    "\n",
    "# customer id\n",
    "df1['customer_id'] = df1['customer_id'].astype( int )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Data Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Numerical attributes ====\n",
    "df2_purchases = df2.loc[df2['unit_price'] >= 0.04, :]\n",
    "\n",
    "# === Categorical attributes ====\n",
    "df2 = df2[~df2['stock_code'].isin( ['POST', 'D', 'DOT', 'M', 'S', 'AMAZONFEE', 'm', 'DCGSSBOY', 'DCGSSGIRL','PADS', 'B', 'CRUK'] )]\n",
    "\n",
    "# description\n",
    "df2 = df2.drop( columns='description', axis=1 )\n",
    "\n",
    "# map \n",
    "df2 = df2[~df2['country'].isin( ['European Community', 'Unspecified' ] ) ]\n",
    "\n",
    "# quantity\n",
    "df2_returns = df2.loc[df1['quantity'] < 0, :]\n",
    "df2_purchases = df2.loc[df1['quantity'] >= 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2_purchases.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF reference\n",
    "df_ref = df3.drop( ['invoice_no', 'stock_code', \n",
    "                    'quantity', 'invoice_date', 'unit_price', \n",
    "                    'country'], axis=1 ).drop_duplicates( ignore_index=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gross Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14013/1522764053.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2_purchases['gross_revenue'] = df2_purchases['quantity'] * df2_purchases['unit_price']\n"
     ]
    }
   ],
   "source": [
    "# Gross revenue\n",
    "df2_purchases['gross_revenue'] = df2_purchases['quantity'] * df2_purchases['unit_price']\n",
    "\n",
    "# Monetary\n",
    "df_monetary = df2_purchases[['customer_id', 'gross_revenue']].groupby('customer_id').sum().reset_index()\n",
    "df_ref = pd.merge(df_ref, df_monetary, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recency - Days since the last purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recency - Last day purchase\n",
    "# **inverter função**\n",
    "df_recency = df2_purchases[['customer_id', 'invoice_date']].groupby( 'customer_id' ).max().reset_index()\n",
    "df_recency['recency_days'] = ( df2_purchases['invoice_date'].max() - df_recency['invoice_date'] ).dt.days\n",
    "df_recency = df_recency[['customer_id', 'recency_days']].copy()\n",
    "# df_recency['recency_days'] = df_recency['recency_days'].apply( lambda x: 1 / x if x != 0 else 0)\n",
    "df_ref = pd.merge( df_ref, df_recency, on='customer_id', how='left' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantity of purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id      0\n",
       "gross_revenue    0\n",
       "recency_days     0\n",
       "qtde_invoices    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numero de produtos\n",
    "df_freq = (df2_purchases.loc[:, ['customer_id', 'invoice_no']].drop_duplicates()\n",
    "                                                             .groupby( 'customer_id' )\n",
    "                                                             .count()\n",
    "                                                             .reset_index()\n",
    "                                                             .rename( columns={'invoice_no': 'qtde_invoices'}) )\n",
    "df_ref = pd.merge( df_ref, df_freq, on='customer_id', how='left' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total of items purchased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id      0\n",
       "gross_revenue    0\n",
       "recency_days     0\n",
       "qtde_invoices    0\n",
       "qtde_items       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numero de produtos\n",
    "df_freq = (df2_purchases.loc[:, ['customer_id', 'quantity']].groupby( 'customer_id' ).sum()\n",
    "                                                           .reset_index()\n",
    "                                                           .rename( columns={'quantity': 'qtde_items'} ) )\n",
    "df_ref = pd.merge( df_ref, df_freq, on='customer_id', how='left' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Totoal of unique products purchased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id      0\n",
       "gross_revenue    0\n",
       "recency_days     0\n",
       "qtde_invoices    0\n",
       "qtde_items       0\n",
       "qtde_products    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numero de produtos\n",
    "df_freq = (df2_purchases.loc[:, ['customer_id', 'stock_code']].groupby( 'customer_id' ).count()\n",
    "                                                           .reset_index()\n",
    "                                                           .rename( columns={'stock_code': 'qtde_products'} ) )\n",
    "df_ref = pd.merge( df_ref, df_freq, on='customer_id', how='left' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avg Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id      0\n",
       "gross_revenue    0\n",
       "recency_days     0\n",
       "qtde_invoices    0\n",
       "qtde_items       0\n",
       "qtde_products    0\n",
       "avg_ticket       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avg Ticket\n",
    "df_avg_ticket = df2_purchases.loc[:, ['customer_id', 'gross_revenue']].groupby( 'customer_id' ).mean().reset_index().rename( columns={'gross_revenue':'avg_ticket'} )\n",
    "df_ref = pd.merge( df_ref, df_avg_ticket, on='customer_id', how='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avg recency days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id         0\n",
       "gross_revenue       0\n",
       "recency_days        0\n",
       "qtde_invoices       0\n",
       "qtde_items          0\n",
       "qtde_products       0\n",
       "avg_ticket          0\n",
       "avg_recency_days    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average recency days\n",
    "df_aux = df2[['customer_id', 'invoice_date']].drop_duplicates().sort_values( ['customer_id', 'invoice_date'], ascending=False )\n",
    "df_aux['next_customer_id'] = df_aux['customer_id'].shift() # next customer\n",
    "df_aux['previous_date'] = df_aux['invoice_date'].shift() # next invoince date\n",
    "\n",
    "df_aux['avg_recency_days'] = df_aux.apply( lambda x: ( x['invoice_date'] - x['previous_date'] ).days if x['customer_id'] == x['next_customer_id'] else 0, axis=1 )\n",
    "# df_aux['avg_recency_days'] = df_aux['avg_recency_days'].apply( lambda x: 1/x if x !=0 else 0)\n",
    "\n",
    "df_aux = df_aux.drop( ['invoice_date', 'next_customer_id', 'previous_date'], axis=1 ).dropna()\n",
    "\n",
    "# average recency \n",
    "df_avg_recency_days = df_aux.groupby( 'customer_id' ).mean().reset_index()\n",
    "\n",
    "# merge\n",
    "df_ref = pd.merge( df_ref, df_avg_recency_days, on='customer_id', how='left' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of purchases\n",
    "- frequency = event / time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id         0\n",
       "gross_revenue       0\n",
       "recency_days        0\n",
       "qtde_invoices       0\n",
       "qtde_items          0\n",
       "qtde_products       0\n",
       "avg_ticket          0\n",
       "avg_recency_days    0\n",
       "frequency           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux = ( df2_purchases[['customer_id', 'invoice_no', 'invoice_date']].drop_duplicates()\n",
    "                                                             .groupby( 'customer_id')\n",
    "                                                             .agg( max_ = ( 'invoice_date', 'max' ), \n",
    "                                                                   min_ = ( 'invoice_date', 'min' ),\n",
    "                                                                   days_= ( 'invoice_date', lambda x: ( ( x.max() - x.min() ).days ) + 1 ),\n",
    "                                                                   buy_ = ( 'invoice_no', 'count' ) ) ).reset_index()\n",
    "# Frequency\n",
    "df_aux['frequency'] = df_aux[['buy_', 'days_']].apply( lambda x: x['buy_'] / x['days_'] if  x['days_'] != 0 else 0, axis=1 )\n",
    "\n",
    "# Merge\n",
    "df_ref = pd.merge( df_ref, df_aux[['customer_id', 'frequency']], on='customer_id', how='left' )\n",
    "\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id         0\n",
       "gross_revenue       0\n",
       "recency_days        0\n",
       "qtde_invoices       0\n",
       "qtde_items          0\n",
       "qtde_products       0\n",
       "avg_ticket          0\n",
       "avg_recency_days    0\n",
       "frequency           0\n",
       "qtde_returns        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Returns\n",
    "df_returns = df2_returns[['customer_id', 'quantity']].groupby( 'customer_id' ).sum().reset_index().rename( columns={'quantity':'qtde_returns'} )\n",
    "df_returns['qtde_returns'] = df_returns['qtde_returns'] * -1\n",
    "\n",
    "df_ref = pd.merge( df_ref, df_returns, how='left', on='customer_id' )\n",
    "df_ref.loc[df_ref['qtde_returns'].isna(), 'qtde_returns'] = 0\n",
    "\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basket Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id         0\n",
       "gross_revenue       0\n",
       "recency_days        0\n",
       "qtde_invoices       0\n",
       "qtde_items          0\n",
       "qtde_products       0\n",
       "avg_ticket          0\n",
       "avg_recency_days    0\n",
       "frequency           0\n",
       "qtde_returns        0\n",
       "avg_basket_size     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux = ( df2_purchases.loc[:, ['customer_id', 'invoice_no', 'quantity']].groupby( 'customer_id' )\n",
    "                                                                            .agg( n_purchase=( 'invoice_no', 'nunique'),\n",
    "                                                                                  n_products=( 'quantity', 'sum' ) )\n",
    "                                                                            .reset_index() )\n",
    "\n",
    "# calculation\n",
    "df_aux['avg_basket_size'] = df_aux['n_products'] / df_aux['n_purchase']\n",
    "\n",
    "# merge\n",
    "df_ref = pd.merge( df_ref, df_aux[['customer_id', 'avg_basket_size']], how='left', on='customer_id' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique Basket Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id               0\n",
       "gross_revenue             0\n",
       "recency_days              0\n",
       "qtde_invoices             0\n",
       "qtde_items                0\n",
       "qtde_products             0\n",
       "avg_ticket                0\n",
       "avg_recency_days          0\n",
       "frequency                 0\n",
       "qtde_returns              0\n",
       "avg_basket_size           0\n",
       "avg_unique_basket_size    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux = ( df2_purchases.loc[:, ['customer_id', 'invoice_no', 'stock_code']].groupby( 'customer_id' )\n",
    "                                                                            .agg( n_purchase=( 'invoice_no', 'nunique'),\n",
    "                                                                                   n_products=( 'stock_code', 'nunique' ) )\n",
    "                                                                            .reset_index() )\n",
    "\n",
    "# calculation\n",
    "df_aux['avg_unique_basket_size'] = df_aux['n_products'] / df_aux['n_purchase']\n",
    "\n",
    "# merge\n",
    "df_ref = pd.merge( df_ref, df_aux[['customer_id', 'avg_unique_basket_size']], how='left', on='customer_id' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df_ref.copy()\n",
    "df4 = df4.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Estudo de espaços"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df43 = df4.drop(columns=['customer_id'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df43.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.4 Tree-based Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df43.drop(columns=['gross_revenue'], axis=1).copy()\n",
    "y = df43['gross_revenue'].copy()\n",
    "\n",
    "# model definiton\n",
    "forest = en.RandomForestRegressor( n_estimators=100, \n",
    "                                  random_state=42,\n",
    "                                   criterion='friedman_mse' )\n",
    "\n",
    "# model training\n",
    "forest.fit( X, y )\n",
    "\n",
    "# predict\n",
    "df_leaf = pd.DataFrame(forest.apply( X ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/natan/miniconda3/envs/mentodeploy/lib/python3.10/site-packages/umap/umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    }
   ],
   "source": [
    "reducer = umap.UMAP( n_neighbors=80, random_state=42 )\n",
    "embedding = reducer.fit_transform( df_leaf )\n",
    "\n",
    "# embedding\n",
    "df_tree = pd.DataFrame()\n",
    "df_tree['embedding_x'] = embedding[:, 0]\n",
    "df_tree['embedding_y'] = embedding[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df5.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0 Hyperparameter Fine-Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.0 Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_tree.copy()\n",
    "# Model definition\n",
    "k = 10\n",
    "kmeans = c.KMeans( init='random', n_clusters=k, n_init=10, random_state=42, max_iter=300 )\n",
    "\n",
    "# model training\n",
    "kmeans.fit( X )\n",
    "\n",
    "# clustering\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Cluster Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12234.1357421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7133088\n"
     ]
    }
   ],
   "source": [
    "# WSS (Within-cluster sum of square)\n",
    "print(kmeans.inertia_)\n",
    "\n",
    "# SS (Silhouette Score)\n",
    "print(metrics.silhouette_score( X, labels, metric='euclidean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.0 Cluster Analyslis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = df6.copy()\n",
    "df9['cluster'] = labels\n",
    "X['cluster'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Cluster Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df9['avg_recency_days'] = df9['avg_recency_days'].apply( lambda x: 1/x if x !=0 else 0)\n",
    "# df9['recency_days'] = df9['recency_days'].apply( lambda x: 1/x if x !=0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of customer\n",
    "df_cluster = df9[['customer_id', 'cluster']].groupby( 'cluster' ).count().reset_index()\n",
    "df_cluster['perc_customer'] = 100*( df_cluster['customer_id'] / df_cluster['customer_id'].sum() )\n",
    "\n",
    "# Avg Gross revenue\n",
    "df_avg_gross_revenue = df9[['gross_revenue', 'cluster']].groupby( 'cluster' ).mean().reset_index()\n",
    "df_cluster = pd.merge( df_cluster, df_avg_gross_revenue, how='inner', on='cluster' )\n",
    "\n",
    "# Avg recency days\n",
    "df_avg_recency_days = df9[['recency_days', 'cluster']].groupby( 'cluster' ).mean().reset_index()\n",
    "df_cluster = pd.merge( df_cluster, df_avg_recency_days, how='inner', on='cluster' )\n",
    "\n",
    "# Avg invoice_no\n",
    "df_invoice_no = df9[['qtde_invoices', 'cluster']].groupby( 'cluster' ).mean().reset_index()\n",
    "df_cluster = pd.merge( df_cluster, df_invoice_no, how='inner', on='cluster' )\n",
    "\n",
    "# Avg Qnt_items\n",
    "df_items_no = df9[['qtde_items', 'cluster']].groupby( 'cluster' ).mean().reset_index()\n",
    "df_cluster = pd.merge( df_cluster, df_items_no, how='inner', on='cluster' )\n",
    "\n",
    "# Avg frequency\n",
    "df_frequency_no = df9[['frequency', 'cluster']].groupby( 'cluster' ).mean().reset_index()\n",
    "df_cluster = pd.merge( df_cluster, df_frequency_no, how='inner', on='cluster' )\n",
    "\n",
    "# Avg returns\n",
    "df_returns_no = df9[['qtde_returns', 'cluster']].groupby( 'cluster' ).mean().reset_index()\n",
    "df_cluster = pd.merge( df_cluster, df_returns_no, how='inner', on='cluster' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>perc_customer</th>\n",
       "      <th>gross_revenue</th>\n",
       "      <th>recency_days</th>\n",
       "      <th>qtde_invoices</th>\n",
       "      <th>qtde_items</th>\n",
       "      <th>frequency</th>\n",
       "      <th>qtde_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>479</td>\n",
       "      <td>11.059801</td>\n",
       "      <td>11225.436701</td>\n",
       "      <td>25.872651</td>\n",
       "      <td>15.181628</td>\n",
       "      <td>6814.043841</td>\n",
       "      <td>0.098949</td>\n",
       "      <td>494.830898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>374</td>\n",
       "      <td>8.635419</td>\n",
       "      <td>2570.682807</td>\n",
       "      <td>41.339572</td>\n",
       "      <td>6.631016</td>\n",
       "      <td>1586.058824</td>\n",
       "      <td>0.107853</td>\n",
       "      <td>22.366310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>445</td>\n",
       "      <td>10.274763</td>\n",
       "      <td>1756.879348</td>\n",
       "      <td>44.058427</td>\n",
       "      <td>5.447191</td>\n",
       "      <td>996.276404</td>\n",
       "      <td>0.075215</td>\n",
       "      <td>20.997753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>573</td>\n",
       "      <td>13.230201</td>\n",
       "      <td>1184.790140</td>\n",
       "      <td>65.394415</td>\n",
       "      <td>3.670157</td>\n",
       "      <td>622.431065</td>\n",
       "      <td>0.161613</td>\n",
       "      <td>10.642234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>433</td>\n",
       "      <td>9.997691</td>\n",
       "      <td>690.503256</td>\n",
       "      <td>91.794457</td>\n",
       "      <td>2.006928</td>\n",
       "      <td>431.879908</td>\n",
       "      <td>0.369581</td>\n",
       "      <td>5.859122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>390</td>\n",
       "      <td>9.004849</td>\n",
       "      <td>555.136436</td>\n",
       "      <td>75.948718</td>\n",
       "      <td>2.835897</td>\n",
       "      <td>262.784615</td>\n",
       "      <td>0.026942</td>\n",
       "      <td>4.056410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>8.404526</td>\n",
       "      <td>400.802143</td>\n",
       "      <td>136.392857</td>\n",
       "      <td>1.123626</td>\n",
       "      <td>256.799451</td>\n",
       "      <td>0.998283</td>\n",
       "      <td>3.675824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>381</td>\n",
       "      <td>8.797045</td>\n",
       "      <td>322.561709</td>\n",
       "      <td>129.078740</td>\n",
       "      <td>1.737533</td>\n",
       "      <td>133.217848</td>\n",
       "      <td>0.537492</td>\n",
       "      <td>1.451444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>242</td>\n",
       "      <td>5.587624</td>\n",
       "      <td>290.750744</td>\n",
       "      <td>140.586777</td>\n",
       "      <td>1.099174</td>\n",
       "      <td>163.413223</td>\n",
       "      <td>1.014587</td>\n",
       "      <td>1.838843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>650</td>\n",
       "      <td>15.008081</td>\n",
       "      <td>169.746046</td>\n",
       "      <td>168.864615</td>\n",
       "      <td>1.256923</td>\n",
       "      <td>59.572308</td>\n",
       "      <td>0.874062</td>\n",
       "      <td>1.756923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster  customer_id  perc_customer  gross_revenue  recency_days  \\\n",
       "7        7          479      11.059801   11225.436701     25.872651   \n",
       "5        5          374       8.635419    2570.682807     41.339572   \n",
       "2        2          445      10.274763    1756.879348     44.058427   \n",
       "4        4          573      13.230201    1184.790140     65.394415   \n",
       "0        0          433       9.997691     690.503256     91.794457   \n",
       "6        6          390       9.004849     555.136436     75.948718   \n",
       "1        1          364       8.404526     400.802143    136.392857   \n",
       "3        3          381       8.797045     322.561709    129.078740   \n",
       "8        8          242       5.587624     290.750744    140.586777   \n",
       "9        9          650      15.008081     169.746046    168.864615   \n",
       "\n",
       "   qtde_invoices   qtde_items  frequency  qtde_returns  \n",
       "7      15.181628  6814.043841   0.098949    494.830898  \n",
       "5       6.631016  1586.058824   0.107853     22.366310  \n",
       "2       5.447191   996.276404   0.075215     20.997753  \n",
       "4       3.670157   622.431065   0.161613     10.642234  \n",
       "0       2.006928   431.879908   0.369581      5.859122  \n",
       "6       2.835897   262.784615   0.026942      4.056410  \n",
       "1       1.123626   256.799451   0.998283      3.675824  \n",
       "3       1.737533   133.217848   0.537492      1.451444  \n",
       "8       1.099174   163.413223   1.014587      1.838843  \n",
       "9       1.256923    59.572308   0.874062      1.756923  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cluster.sort_values('gross_revenue', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.0 Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.0 Insert into SQLITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Database connection details\n",
    "host = 'mentoria-db.cj8omc2s6yze.us-east-1.rds.amazonaws.com'\n",
    "port = '5432'\n",
    "database = 'postgres'\n",
    "user = 'postgres'\n",
    "pwd = '12345678'\n",
    "\n",
    "# Connection string\n",
    "endpoint = f'postgresql://{user}:{pwd}@{host}:{port}/{database}'\n",
    "engine = create_engine(endpoint)\n",
    "\n",
    "# SQL query to create the table\n",
    "query_create_table_insiders = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS insiders (\n",
    "        customer_id             INTEGER,\n",
    "        gross_revenue           REAL,\n",
    "        recency_days            REAL,\n",
    "        qtde_invoices           INTEGER,\n",
    "        qtde_items              INTEGER,\n",
    "        qtde_products           INTEGER,\n",
    "        avg_ticket              REAL,\n",
    "        avg_recency_days        REAL,\n",
    "        frequency               REAL,\n",
    "        qtde_returns            REAL,\n",
    "        avg_basket_size         REAL,\n",
    "        avg_unique_basket_size  REAL,\n",
    "        revenue_returned        REAL,\n",
    "        cluster                 INTEGER\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query as raw SQL\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(query_create_table_insiders))\n",
    "\n",
    "# Write DataFrame to the 'insiders' table\n",
    "df9.to_sql('insiders', con=engine, if_exists='append', index=False)\n",
    "conn.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
